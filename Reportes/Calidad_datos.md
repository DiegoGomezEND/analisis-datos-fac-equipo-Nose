#  Análisis de Calidad de Datos FAC

Este documento contiene el script en **Python** para el análisis de calidad de datos,
adaptado al rol de *Estudiante C (Calidad de Datos)* dentro del proyecto colaborativo.

---

##  Archivo: `calidad_datos.py`

```python
# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p0cyccXvgY8AdzeeJHj26UVV33_94-Ar
"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
calidad_datos.py – Estudiante C (Calidad de Datos)
Enfoque: estadística aplicada + chequeos espaciales básicos.
Salida: todo en consola.
"""

import pandas as pd
import numpy as np

# Ruta fija en Colab
INFILE = "/content/JEFAB_2024.xlsx"

# -------------------- Utilidades --------------------
def safe_col(df, col):
    return col in df.columns

def iqr_outlier_bounds(series, k=1.5):
    q1, q3 = series.quantile([0.25, 0.75])
    iqr = q3 - q1
    return q1 - k * iqr, q3 + k * iqr

# -------------------- Main --------------------
def main():
    # 1) Carga de datos
    df = pd.read_excel(INFILE)
    df.columns = (
        df.columns.str.strip()
        .str.replace(r"\s+", "_", regex=True)
        .str.upper()
    )

    print("=== INFORMACIÓN GENERAL ===")
    print(f"Filas: {df.shape[0]} | Columnas: {df.shape[1]}")
    print(f"Primeras columnas: {list(df.columns[:10])}\n")

    # 2) Faltantes
    print("=== ANÁLISIS DE FALTANTES ===")
    n = len(df)
    miss = df.isna().sum().to_frame("N_FALTANTES")
    miss["PORC_FALTANTES"] = (miss["N_FALTANTES"] / n) * 100
    miss = miss[miss["N_FALTANTES"] > 0].sort_values("PORC_FALTANTES", ascending=False)

    # Mostrar top 15 columnas con más nulos
    print(miss.head(15))
    print(f"\nColumnas con al menos un nulo: {miss.shape[0]} / {df.shape[1]}\n")

    # 3) Duplicados
    print("=== ANÁLISIS DE DUPLICADOS ===")
    print(f"Duplicados fila completa: {df.duplicated().sum()}\n")

    # 4) Tipos de datos
    print("=== TIPOS DE DATOS ===")
    print(df.dtypes.value_counts(), "\n")

    # 5) Chequeos básicos de plausibilidad
    print("=== CHEQUEOS DE PLAUSIBILIDAD ===")
    if safe_col(df, "EDAD2"):
        s = pd.to_numeric(df["EDAD2"], errors="coerce")
        invalid = s[(s < 15) | (s > 90)]
        print(f"Edades fuera de rango (15–90): {invalid.shape[0]} casos")

    if safe_col(df, "NUMERO_HIJOS") and safe_col(df, "HIJOS_EN_HOGAR"):
        a = pd.to_numeric(df["NUMERO_HIJOS"], errors="coerce")
        b = pd.to_numeric(df["HIJOS_EN_HOGAR"], errors="coerce")
        invalid = (a < b).sum()
        print(f"Hogares con HIJOS_EN_HOGAR > NUMERO_HIJOS: {invalid} casos")

    if safe_col(df, "ESTRATO"):
        s = pd.to_numeric(df["ESTRATO"], errors="coerce")
        invalid = s[(s < 0) | (s > 6)].shape[0]
        print(f"Estratos fuera de rango (0–6): {invalid} casos")
    print()

    # 6) Outliers numéricos (por IQR)
    print("=== DETECCIÓN DE OUTLIERS (IQR) ===")
    num_cols = df.select_dtypes(include=[np.number]).columns
    for col in num_cols[:5]:  # solo las primeras 5 numéricas
        s = df[col].dropna()
        if s.empty:
            continue
        lo, hi = iqr_outlier_bounds(s)
        n_out = ((s < lo) | (s > hi)).sum()
        if n_out > 0:
            print(f"{col}: {n_out} outliers ({(n_out/len(s))*100:.2f}%)")
    print()

    # 7) Chequeo espacial ligero
    print("=== CHEQUEO ESPACIAL LIGERO ===")
    for col in ["UNIDAD", "CIUDAD", "CATEGORIA"]:
        if safe_col(df, col):
            s = df[col]
            print(f"{col}: {s.nunique()} valores únicos, {s.isna().mean()*100:.2f}% nulos")
            print(f"Top 5 categorías: {list(s.value_counts().head().index)}")
    print()

    print("=== ANÁLISIS DE CALIDAD COMPLETADO ===")

if __name__ == "__main__":
    main()

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
calidad_datos.py – Estudiante C (Calidad de Datos)
Versión ajustada: Selección de 30 variables relevantes
"""

import pandas as pd
import numpy as np

# Ruta fija en Colab
INFILE = "/content/JEFAB_2024.xlsx"

# Lista de 30 variables seleccionadas
TOP30_VARS = [
    "ID","UNIDAD","CATEGORIA","GRADO","CUERPO","SEXO","GENERO","EDAD2",
    "ESTADO_CIVIL","NIVEL_EDUCATIVO","ESTRATO","HIJOS","NUMERO_HIJOS",
    "HIJOS_EN_HOGAR","VIVIENDA_PROPIA","HABITA_VIVIENDA_FAMILIAR",
    "TIPO_VIVIENDA","NUMERO_HABITAN_VIVIENDA",
    "NUMERO_PERSONAS_APORTE_SOSTENIMIENTO","INGRESO_MENSUAL","GASTO_MENSUAL",
    "SERVICIOS_PUBLICOS","ACCESO_SALUD","SEGURIDAD_SOCIAL",
    "EDAD_PADRE","EDAD_MADRE","MADRE_VIVE_SI","PADRE_VIVE_SI",
    "DEPORTE_PRACTICA","TIEMPO_LIBRE"
]

def safe_col(df, col):
    return col in df.columns

def iqr_outlier_bounds(series, k=1.5):
    q1, q3 = series.quantile([0.25, 0.75])
    iqr = q3 - q1
    return q1 - k * iqr, q3 + k * iqr

def main():
    # 1) Carga de datos
    df = pd.read_excel(INFILE)
    df.columns = (
        df.columns.str.strip()
        .str.replace(r"\s+", "_", regex=True)
        .str.upper()
    )

    # Subconjunto de 30 variables
    cols_final = [c for c in TOP30_VARS if c in df.columns]
    df = df[cols_final]

    print("=== INFORMACIÓN GENERAL ===")
    print(f"Filas: {df.shape[0]} | Columnas: {df.shape[1]}")
    print(f"Columnas finales: {list(df.columns)}\n")

    # 2) Faltantes
    print("=== ANÁLISIS DE FALTANTES ===")
    n = len(df)
    miss = df.isna().sum().to_frame("N_FALTANTES")
    miss["PORC_FALTANTES"] = (miss["N_FALTANTES"] / n) * 100
    miss = miss[miss["N_FALTANTES"] > 0].sort_values("PORC_FALTANTES", ascending=False)
    print(miss.head(15))
    print(f"\nColumnas con al menos un nulo: {miss.shape[0]} / {df.shape[1]}\n")

    # 3) Duplicados
    print("=== ANÁLISIS DE DUPLICADOS ===")
    print(f"Duplicados fila completa: {df.duplicated().sum()}\n")

    # 4) Tipos de datos
    print("=== TIPOS DE DATOS ===")
    print(df.dtypes.value_counts(), "\n")

    # 5) Chequeos de plausibilidad
    print("=== CHEQUEOS DE PLAUSIBILIDAD ===")
    if safe_col(df, "EDAD2"):
        s = pd.to_numeric(df["EDAD2"], errors="coerce")
        invalid = s[(s < 15) | (s > 90)]
        print(f"Edades fuera de rango (15–90): {invalid.shape[0]} casos")

    if safe_col(df, "NUMERO_HIJOS") and safe_col(df, "HIJOS_EN_HOGAR"):
        a = pd.to_numeric(df["NUMERO_HIJOS"], errors="coerce")
        b = pd.to_numeric(df["HIJOS_EN_HOGAR"], errors="coerce")
        invalid = (a < b).sum()
        print(f"Hogares con HIJOS_EN_HOGAR > NUMERO_HIJOS: {invalid} casos")

    if safe_col(df, "ESTRATO"):
        s = pd.to_numeric(df["ESTRATO"], errors="coerce")
        invalid = s[(s < 0) | (s > 6)].shape[0]
        print(f"Estratos fuera de rango (0–6): {invalid} casos")
    print()

    # 6) Outliers numéricos (por IQR)
    print("=== DETECCIÓN DE OUTLIERS (IQR) ===")
    num_cols = df.select_dtypes(include=[np.number]).columns
    for col in num_cols[:5]:
        s = df[col].dropna()
        if s.empty:
            continue
        lo, hi = iqr_outlier_bounds(s)
        n_out = ((s < lo) | (s > hi)).sum()
        if n_out > 0:
            print(f"{col}: {n_out} outliers ({(n_out/len(s))*100:.2f}%)")
    print()

    # 7) Chequeo espacial ligero
    print("=== CHEQUEO ESPACIAL LIGERO ===")
    for col in ["UNIDAD", "CATEGORIA"]:
        if safe_col(df, col):
            s = df[col]
            print(f"{col}: {s.nunique()} valores únicos, {s.isna().mean()*100:.2f}% nulos")
            print(f"Top 5 categorías: {list(s.value_counts().head().index)}")
    print()

    print("=== ANÁLISIS DE CALIDAD COMPLETADO ===")

if __name__ == "__main__":
    main()
```
---

## Conclusión
Este script permite:
- Detectar valores faltantes y duplicados.
- Identificar inconsistencias de plausibilidad.
- Reconocer outliers con criterio estadístico (IQR).
- Seleccionar un **subconjunto de 30 variables clave** para análisis posteriores.

---

 **Autor:** Estudiante C – *Calidad de Datos*
